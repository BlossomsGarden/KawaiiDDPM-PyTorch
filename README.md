# ğŸ‘‹ Welcome!

çº¦ 600 è¡Œä»£ç ï¼Œä»é›¶å¼€å§‹åšä¸€ä¸ªç”ŸæˆäºŒæ¬¡å…ƒå¥³å­©å¤´åƒçš„ç”Ÿæˆå¼æ¨¡å‹ï¼

åŸ DDPM è®ºæ–‡çš„å¼€æºä»£ç æ˜¯tensorflowåº“å®ç°çš„ï¼Œä½†æ˜¯tfç¯å¢ƒå¤ªå¤æ‚äº†è¿˜æœ‰v1v2å…¼å®¹æ€§é—®é¢˜ï¼Œçªå‘å¥‡æƒ³è¦ä¸ä½¿ç”¨ PyTorch å¤ç° DDPM ä»£ç ï¼Ÿè™½ç„¶ç½‘ä¸Šå·²ç»æœ‰å‰äººå¼€è¾Ÿå¥½äº†é“è·¯ï¼Œä½†ä¸€ç›´æ²¡æœ‰æ—¶é—´ä»˜è¯¸å®è·µï¼Œä¸å¦‚åˆšå¥½è¶è€ƒç ”ç»“æŸçš„å‡ ä¸ªæœˆå°†è¿™æ¡è·¯èµ°å®Œï¼Ÿ
![dataset-cover](https://github.com/user-attachments/assets/a5e330ce-454e-4070-a10f-63a339c06c6d)


# ğŸ”§ å‡†å¤‡å·¥ä½œ

### æ•°æ®é›† (Kaggleæ˜¯ç¥)
- [Anime Faces](https://www.kaggle.com/datasets/soumikrakshit/anime-faces) 21551 å¼ ï¼Œ64*64 åƒç´ ï¼Œå­˜åœ¨å°‘æ•°éå¤´åƒã€å¤±çœŸã€é‡å¤å›¾ç‰‡
- [Anime Face Dataset](https://www.kaggle.com/datasets/splcher/animefacedataset/data) 63632 å¼ ï¼Œæ­£æ–¹å½¢ï¼Œå¤§å°ä¸ç»Ÿä¸€

### è®ºæ–‡
- [Denoising Diffusion Probabilistic Models](https://dl.acm.org/doi/abs/10.5555/3495724.3496298) (2020)
- [Attention is All You Need](https://dl.acm.org/doi/10.5555/3295222.3295349) (2017)

### æºç 
- [å®˜æ–¹ diffusion_tf](https://github.com/hojonathanho/diffusion)
- [æ°‘é—´ diffusion_torch](https://github.com/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/diffusion/ddpm)

### è§£è¯´
- [æ¨¡å‹æ¶æ„ï¼ˆæ–‡ç« ï¼‰](https://zhuanlan.zhihu.com/p/637815071)
- [æºç è§£è¯»ï¼ˆæ–‡ç« ï¼‰](https://zhuanlan.zhihu.com/p/655568910)


![Bad Deepseek](https://github.com/user-attachments/assets/f791ff38-32b9-4abb-8f35-fea3d69a2e16)



# ğŸ‘¨â€ğŸ’» Attention

DDPM è®ºæ–‡ç»™å‡ºçš„æºç ä¸­æ³¨æ„åŠ›æœºåˆ¶éå¿…é¡»ï¼Œè€Œä¸”å®ç°æ–¹å¼ä¸æ“å¤©æŸ±(Transformer)ä¸€æ ·ã€‚å­¦ä¹ è·¯å¾„å¦‚ä¸‹ã€‚ä½†æ„Ÿè§‰è¿˜æ˜¯å¤ªæŠ½è±¡äº†ï¼Œç”¨æ•°æ®é¢„æµ‹çš„ä¾‹å­å¾ˆå¥½ç†è§£ï¼Œå³èƒ½è®©é¢„æµ‹å€¼æ›´æ¥è¿‘æ ·æœ¬çš„ç©ºé—´åˆ†å¸ƒçŠ¶å†µï¼Œä½†è¦æ˜¯æ”¾åœ¨ LLM æˆ–è€… DDPM é‡Œï¼Œè„‘å­ä¸€ä¸‹å­è¿ç§»ä¸è¿‡æ¥

- [å­¦æœ¯æ€§ä»‹ç»](https://www.bilibili.com/video/BV1TZ421j7Ke)
- [é€šä¿—æ˜“æ‡‚ä»‹ç»](https://www.bilibili.com/video/BV1dt4y1J7ov) ï¼ˆæ³¨æ„è¯„è®ºåŒºç½®é¡¶ï¼‰
- [æ²ç¥ä»‹ç»ä¸ç®€å•ä»£ç ](https://www.bilibili.com/video/BV1264y1i7R1) 



# ğŸ’¿ DDPMÂ·Unet æ¶æ„

ä»¥[çŸ¥ä¹@çŒ›çŒ¿]()å¤§ä½¬çš„è§£è¯´å›¾ä¸ºåŸºç¡€ï¼Œä¿®æ”¹äº†åŸå›¾çš„ä½ç½®ã€åšå‡ºäº†æ–°çš„æ ‡æ³¨ï¼Œä½¿å¾—æœ¬ä»“åº“ä¸­ `unet.py` æ–‡ä»¶ä¸­çš„ æ¨¡å‹ç›¸å…³ç±»ã€å›¾åƒé€šé“æ•° ç­‰ä¿¡æ¯éƒ½å¯ä»¥åœ¨å›¾ä¸­æ‰¾åˆ°å¯¹åº”ï¼Œæ–¹ä¾¿ç†è§£

![Unet](./readme-assets/unet.png)

ç›¸åº”åœ°ï¼Œæœ¬é¡¹ç›® unet ç½‘ç»œä¸­çš„ Encoder å’Œ Decoder ç›´æ¥ä½¿ç”¨ nn.Sequential(...) é“ºå±•å¼€çš„å½¢å¼å®ç°ï¼Œæ›´ä¸ºç›´è§‚ã€‚

    self.encoder=nn.Sequential(
        # 1st Encoder
        DownBlock(in_channels=64, out_channels=64, time_channels=256, attention=False),
        DownBlock(in_channels=64, out_channels=64, time_channels=256, attention=False),
        
        Downsample(n_channels=64),

        # 2nd Encoder
        DownBlock(in_channels=64, out_channels=128, time_channels=256, attention=False), 
        DownBlock(in_channels=128, out_channels=128, time_channels=256, attention=False),
        
        Downsample(n_channels=128),

        # 3rd Encoder
        DownBlock(in_channels=128, out_channels=256, time_channels=256, attention=True),
        DownBlock(in_channels=256, out_channels=256, time_channels=256, attention=True),
        
        Downsample(n_channels=256),
        # 4th Encoder

        DownBlock(in_channels=256, out_channels=1024, time_channels=256, attention=True),
        DownBlock(in_channels=1024, out_channels=1024, time_channels=256, attention=True)
    )



# ğŸ’¡ è®­ç»ƒé…ç½®

### æ•°æ®é›†

ä¸¤ä¸ªæ•°æ®é›†åˆå¹¶åï¼Œäººå·¥åˆ é™¤äº†éƒ¨åˆ†ä¸å¤´åƒæ— å…³çš„å›¾ç‰‡ï¼ˆå¦‚åªæœ‰è¡£æœã€å¤´å‘ç­‰ç­‰ç‘•ç–µå›¾ç‰‡ï¼‰ï¼Œç¡®ä¿æ•°æ®è´¨é‡ï¼Œå…± 78,698 å¼ ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ä¸º PNG æ ¼å¼ã€‚è‡ªå®šä¹‰ MyAnimeDataset ç±»åŠ è½½æ•°æ®é›†ï¼Œè¯»å–æ—¶åŠ äº†éšæœºæ°´å¹³ç¿»è½¬ã€‚å…¶ä¸­ __getItem__() æ–¹æ³•ä¸­ç´¢å¼•å›¾ç‰‡çš„æ–¹å¼å¦‚ä¸‹ï¼š
    
    img_name = os.path.join(self.dataset_dir, f"{idx + 1}.png") 

å› æ­¤è¦æ±‚æ•°æ®é›†å‘½åå¿…é¡»æ˜¯ 1.png, 2.png, ..., ä¾æ¬¡é€’å¢ï¼ˆåŸºäº `util.py` ä¸­çš„ handle2dataset å‡½æ•°å®ç°ï¼‰


### è®­ç»ƒå‚æ•°

 - `batch_size:` 64
 - `learning_rate:` 1e-5
 - `optimizer:` Adams
 - `num_steps:` 1000 (Sample æ—¶ä¹Ÿè¦ç›¸åº”åœ°é™å™ª 1000 æ­¥æ‰èƒ½å‡ºæ•ˆæœï¼Œå°‘äº†å…¨æ˜¯å™ªå£°ï¼Œå¤šäº†ä¼šæŠ¥é”™)
 - `epochs:` 50


### é¡¹ç›®æ¶æ„
 - `unet.py:` unet ç½‘ç»œçš„å®ç°
 - `train.py:` åŒ…æ‹¬ï¼š1.æ•°æ®é›†é¢„å¤„ç† -> 2.æ•°æ®é›†åŠ è½½ -> 3.DDPMæ¨¡å‹(è°ƒç”¨Unetæ¨¡å—) -> 4.Training (Algorithm1) å’Œ Sampling (Alogrithm2) -> 5.è®¾ç½®å‚æ•°å¼€è®­
 - `util.py:` 2 ä¸ªå·¥å…·å‡½æ•°ï¼Œç”¨äºåˆå¹¶ 2 ä¸ªå¼€æºæ•°æ®é›†ã€æ–°å»ºç©ºæ–‡ä»¶å¤¹
 - `eval.py:` åŒ…æ‹¬åŠ è½½æ¨¡å‹é‡‡æ ·

 - `train.sh:` è®­ç»ƒå¯åŠ¨è„šæœ¬ï¼Œè‹¥æ­£åœ¨è®­ç»ƒåˆ™åœæ­¢å¹¶é‡å¯ï¼Œè‹¥æœªå¼€å§‹è®­ç»ƒåˆ™ç›´æ¥å¯åŠ¨
 - `nohup.out:` è®­ç»ƒè¾“å‡ºï¼ŒæŸå¤±å€¼å¯ä¾›å‚è€ƒ
 - `ddpm-model-45.ckpt:` è®­ç»ƒ 45 epoch çš„æ¨¡å‹ã€‚åœ¨ `eval.py` ä¸­æ”¹æ”¹ torch.load() è·¯å¾„åŠ è½½åç›´æ¥ `python eval.py` å¯åŠ¨çœ‹çœ‹æ•ˆæœ


### å¯åŠ¨
 - è®­ç»ƒï¼š `sh train.sh`

æ¯10è½®ä¿å­˜ä¸€æ¬¡æ¨¡å‹ï¼ŒåŒæ—¶å¯¹16å¼ å™ªå£°å›¾è¿›è¡Œ 1000 æ­¥é™å™ªæ£€éªŒæ•ˆæœã€‚å•å›¾ç‰‡é™å™ªè¿‡ç¨‹ä¿å­˜ä¸º 1.png ~ 16.pngï¼Œ 16å¼ å›¾ç‰‡çš„æœ€ç»ˆç»“æœå±•ç¤ºä¿å­˜ä¸º 16-imgs-final.pngã€‚

 - éªŒè¯ï¼š `python eval.py` 

æ”¹å¥½é‡Œé¢çš„æ¨¡å‹è·¯å¾„ï¼Œç›´æ¥ python eval.py å³å¯ã€‚



# ğŸ’Š ç‚¼ä¸¹ç»“æœ

ç§Ÿç”¨ RTX4090/40Gï¼Œ1 epoch çº¦ 4minï¼Œå…± 50 ä¸ª epochã€‚å‰ 2 ä¸ª loss ç›´æ¥ 0.2023 -> 0.0597ï¼Œçº¦ 45 è½®æ”¶æ•›ï¼Œloss ç¨³å®šåœ¨ 0.0163 é™„è¿‘ã€‚å…¶ä¸­ DDPM.unet() çº¦ 300w å‚æ•°ï¼Œå°† DDPM æ•´ä¸ªä¿å­˜ä¸‹æ¥ 644MBã€‚

### æœªæ”¶æ•›æ—¶é‡‡æ ·1000æ­¥ï¼ˆ9 epochï¼‰
![9-epoch-sample-1](./readme-assets/9-epoch-sample-1.png)
![9-epoch-sample-2](./readme-assets/9-epoch-sample-2.png)
![9-epoch-sample-3](./readme-assets/9-epoch-sample-3.png)
![9-epoch-sample-4](./readme-assets/9-epoch-sample-4.png)
![9-epoch-sample-5](./readme-assets/9-epoch-sample-5.png)
![9-epoch-sample](./readme-assets/9-epoch-sample.png)

### æœªæ”¶æ•›æ—¶é‡‡æ ·1000æ­¥ï¼ˆ27 epochï¼‰
![27-epoch-sample-1](./readme-assets/27-epoch-sample-1.png)
![27-epoch-sample-2](./readme-assets/27-epoch-sample-2.png)
![27-epoch-sample-3](./readme-assets/27-epoch-sample-3.png)
![27-epoch-sample-4](./readme-assets/27-epoch-sample-4.png)
![27-epoch-sample-5](./readme-assets/27-epoch-sample-5.png)
![27-epoch-sample](./readme-assets/27-epoch-sample.png)

### æ”¶æ•›åé‡‡æ ·1000æ­¥ï¼ˆ45epochï¼‰
![45-epoch-sample-1](./readme-assets/45-epoch-sample-1.png)
![45-epoch-sample-2](./readme-assets/45-epoch-sample-2.png)
![45-epoch-sample-3](./readme-assets/45-epoch-sample-3.png)
![45-epoch-sample-4](./readme-assets/45-epoch-sample-4.png)
![45-epoch-sample-5](./readme-assets/45-epoch-sample-5.png)
![45-epoch-sample](./readme-assets/45-epoch-sample.png)



# ğŸ¤¯ è¸©å‘

1. å®ä¾‹åŒ– Unet ä¸€å®šè¦ to(device)ï¼Œå¦åˆ™é»˜è®¤æƒé‡æ˜¯ cpu å¯¼è‡´ device å†²çª

    ```python
    unet = Unet().to(device)
    ```

2. æ¨¡å‹ä¼ å‚å†™å¥½ç±»å‹ï¼Œæ­¥é•¿ t ä»€ä¹ˆæ—¶å€™æ˜¯ int ä»€ä¹ˆæ—¶å€™æ˜¯ Tensor ä¸€ç›®äº†ç„¶

    ```python
    def diffuse(self, x0: torch.Tensor, t:torch.Tensor, noise=None):
    ```

3. ä¸€å®šè¦è®°å¾— Sampling æ—¶ä¼ å…¥ unet çš„æ­¥é•¿ä¾æ¬¡æ˜¯ t-1, t-2, â€¦, 1, 0ï¼ˆä¸è¿‡å¦‚æœç›´æ¥ reverse(range(t)) ä¼šå¯¼è‡´ tqdm è¿›åº¦æ¡å¤±æ•ˆï¼Œå› æ­¤åœ¨å¾ªç¯å†…åšå¤„ç†ï¼‰

    ```python
    for _t in tqdm(range(t), desc=prompt, ncols=100):
        current_step = t - _t - 1   # å½“å‰æ—¶é—´æ­¥ (t-1 åˆ° 0)
    ```